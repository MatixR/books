# *Chapter 23*<br>   Electrostatics via Finite Elements 


| | | |
|:---:|:---:|:---:|
| ![image](Figs/Cover.png)|[From **COMPUTATIONAL PHYSICS**, 3rd Ed, 2015](http://physics.oregonstate.edu/~rubin/Books/CPbook/index.html) <br>RH Landau, MJ Paez, and CC Bordeianu (deceased) <br>Copyrights: <br> [Wiley-VCH, Berlin;](http://www.wiley-vch.de/publish/en/books/ISBN3-527-41315-4/) and [Wiley & Sons, New York](http://www.wiley.com/WileyCDA/WileyTitle/productCd-3527413154.html)<br>  R Landau, Oregon State Unv, <br>MJ Paez, Univ Antioquia,<br> C Bordeianu, Univ Bucharest, 2015.<br> Support by National Science Foundation.|![image](Figs/BackCover.png)|

**23 Electrostatics via Finite Elements**<br>
[23.1 Finite-Element Method](#23.1)<br>
[23.2 Electric Field from Charge Density (Problem)](#23.2)<br>
[23.3 Analytic Solution](#23.3)<br>
[23.4 Finite-Element (Not Difference) Methods, 1-D](#23.4)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.4.1 Weak Form of PDE](#23.4.1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.4.2 Galerkin Spectral Decomposition](#23.4.2)<br>
[23.5 1-D FEM Implementation and Exercises](#23.5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.5.1 1-D Exploration](#23.5.1)<br>
[23.6 Extension to 2-D Finite Elements](#23.6)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.1 Weak Form of PDE](#23.6.1)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.2 Galerkin’s Spectral Decomposition](#23.6.2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.3 Triangular Elements](#23.6.3)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.4 Solution as Linear Equations](#23.6.4)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.5 Imposing Boundary Conditions](#23.6.5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.6 FEM 2D Implementation & Exercise](#23.6.6)<br>
&nbsp;&nbsp;&nbsp;&nbsp;[23.6.7 FEM 2D Exercises](#23.6.7)<br>

*In [Chapter 19](CP19.ipynb) we discussed the simple, but powerful, finite-differences method for solving Poisson's
    and Laplace's equations on a lattice in space. In this chapter we provide a basic outline of the finiteelements
    method (FEM) for solving PDE's. Our usual approach to solving PDE's uses the finite
    difference method to approximate various derivatives in terms of the finite differences of a function
    evaluated upon a fixed grid. The finite-elements method, in contrast, breaks space up into multiple
    geometric objects (elements), determines an approximate form for the solution appropriate to each
    element, and then matches the solutions up at the elements' edges. The finite elements method is
    ultimately more efficient and powerful that the finite differences method, however it is much more
    work to derive the algorithm. In practise, it is rare to solve a PDE from scratch by deriving the
    FEM for a particular problem. Rather, and for good reasons, many FEM applications use highly
    developed FEM packages that get customized for an individual problem. (Python's finite element
    library is FiPy.) Because our aim in this chapter is to give the reader some basic understanding of
    the finite elements method, not to develop a practitioner. Accordingly, we examine a 1-D problem in
    some detail, and then outline the similar steps followed for the same equation extended to 2-D.*

** This Chapter’s Lecture, Slide Web Links, Applets & Animations**

| | |
|---|---|
|[All Lectures](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|[![anything](Figs/RHLlectureMod4.png)](http://physics.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/index.html)|

| *Lecture (Flash)*| *Slides* | *Sections*|*Lecture (Flash)*| *Slides* | *Sections*|  
|- - -|:- - -:|:- - -:|- - -|:- - -:|:- - -:|
| [Intro to PDE’s](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/PDE_Intro/PDE_Intro.html)|[pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pd/PDE's_08Mar.pdf) |19.1 |[PDE Electrostatics I](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Elec1/Elec1.html)|[pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides_NoAnimate_pdf/ElectricField_10Mar.pdf)| 19.2 | 
| [Electrostatics II](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Elec2/Elec2.html) | [pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/ElectricField_10Mar.pdf)|19.4 | [Finite Elements Electrostatics](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/FEM/FEM.html)|[pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/FiniteElements_26May.pdf)| 23| 
| [PDE Heat](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Heat/Heat.html) |[pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/Heat_06Ap10.pdf)|20|[Heat Crank-N](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Modules/Heat_CN/Heat_CN.html)|[pdf](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Lectures/Slides/Slides_NoAnimate_pdf/HeatCrank_96Ap10.pdf)| 20.4|
|[Heat Equation Applet](http://science.oregonstate.edu/~rubin/Books/CPbook/eBook/Applets/index.html)|-|17.16–17.18| | | |

## 23.1  Finite-Element Method $\odot$ <a id="23.1"></a>

The theory and practice of FEM as a numerical method for solving partial
differential equations have been developed over the last 30 years and is
still an active field of research. One of the theoretical strengths of
FEM is that its mathematical foundations allow for elegant proofs of the
convergence of its solutions. One of the practical strengths of FEM is
that it offers great flexibility for problems on irregular domains, or
for problems with highly varying conditions or even singularities.
Although finite differences methods are simpler to implement than FEM,
they are less robust mathematically and for big problems less efficient
in terms of computer time. Finite elements, in turn, are more
complicated to implement, but more appropriate and precise for
complicated equations and complicated geometries. In addition, the same
basic finite-elements technique can be applied to many problems with
only minor modifications, and yields solutions that may be evaluated
throughout all space, not just on a grid. In fact, the finite-elements
method with various preprogrammed multigrid packages has very much
become the standard for large-scale engineering applications. Our
discussion is based upon \[[Shaw(92)](BiblioLinked.html#shaw), [Li(14)](BiblioLinked.html#Li), [Otto(11)](BiblioLinked.html#Otto)\].

## 23.2 Electric Field from Charge Density (Problem)  <a id="23.2"></a>

![image](Figs/Fig23_1.png)

**Figure 23.1** A finite elements solution to Laplace’s equation for two metal
plates with a charge density between them. The dots are the nodes
$\textit{x}_\textit{i}$, and the lines connecting the nodes are the finite
elements.

As shown in Figure 23.1, you are given two conducting plates a distance
$b-a$ apart, with the lower one kept at potential $U_a$, the upper plate
at potential $U_b$, and a uniform charge density $\rho(x)$ placed
between them. Your **problem** is to compute the electric potential
between the plates.

## 23.3  Analytic Solution  <a id="23.2"></a>

The relation between charge density $\rho(\mathbf{x})$ and potential
$U(\mathbf{x})$ is given by Poisson’s equation (19.6). For our problem, the
potential $U$ changes only in the $x$ direction, and so the PDE becomes the
ODE:

$$\tag*{23.1}
\frac{d^2 U(x)}{d x^2} = -4\pi \rho(x) = -1, \quad 0<x<1,$$

where we
have set $\rho(x)= 1/4\pi$ to simplify the programming. The solution we want is
subject to the Dirichlet boundary conditions:

$$\begin{align}
\tag*{23.2}
U(x=a=0) &= 0, \qquad U(x=b=1) = 1,\\
\Rightarrow \quad U(x) &=  -{\frac{x}{2}} (x-3). \tag*{23.3}\end{align}$$

Although we know the analytic solution (23.3), we shall develop the
finite-elements method for solving the ODE as if it were a PDE (it would
be in 2-D), and as if we did not know the solution. Although we will not
demonstrate it, this method works equally well for any charge density
$\rho(x)$.

## 23.4  Finite-Element (Not Difference) Methods, 1-D  <a id="23.4"></a>

In a finite-elements method, the domain in which the PDE is solved is
split into finite subdomains, called *elements*, and a *trial solution*
to the PDE in each subdomain is hypothesized. Then the parameters of the
trial solution are adjusted to obtain a *best fit* (in the sense of
[Chapter 7, *Trial-and-Error Searching & Data Fitting*](CP07.ipynb)) to
the exact solution. Essentially, this approach converts a given PDE into
an integral equation known as the *weak* or *variational* form (“weak”
because there is no longer the requirement that the second derivative of
the solution exists). A trial solution on each element is then
postulated, and this leads to the numerically intensive work of finding
the best values for the parameters in the trial solution, and in
matching up the various trial solutions from different subdomains.

In general, a FEM solution follows six steps \[[Li(14)](BiblioLinked.html#Li)\]:

1.  Derivation of a *weak form* of the PDE. This is equivalent to a
    least-squares minimization of the integral of the difference between
    the approximate and exact solutions.

2.  Discretization of the computational domains.

3.  Generation of interpolating or trial functions.

4.  Conversion of the “weak form” integral equation into a set of
    linear equations.

5.  Implementation of the boundary conditions.

6.  Solution of the resulting linear system of equations.

### 23.4.1  Weak Form of PDE <a id="23.4.1"></a>

Finite-difference methods yield an approximate solution of an approximate PDE.
Finite-element methods yield the best possible global agreement between an
approximate solution and the exact solution. We start the FEM with the
differential equation we want to solve, 

$$\begin{align}
\tag*{23.4}
 -\frac{d^2 U(x)}{dx^2}= 4\pi\rho(x).\end{align}$$ 
 
We form an integral
of the product of the exact solution $U(x)$ and the approximate solution or
*trial solution* $\Phi(x)$ over the solution domain. This will be used as a
measure of overall agreement between the two solutions. We assume that the
trial vanishes at the endpoints, $\Phi(a) = \Phi(b) =0$ (we satisfy general
boundary conditions later). We next multiply both sides of the differential
equation (23.1) by $\Phi$ and integrate by parts from $a$ to $b$:

$$\begin{align} \tag*{23.5}
- \frac{d^2 U(x)} { dx^2} \Phi(x) & = 4\pi\rho(x) \Phi(x),\\
 -\int_a^b dx   \frac{d^2 U(x)}{dx^2}\Phi(x)  &=  \int_a^b\ dx
4\pi\rho(x) \Phi(x) \tag*{23.6}\\
- \frac{d U(x)}{dx}\Phi(x) |_a^b+\int_a^b dx
\frac{d U(x)}{dx}\Phi'(x) &= \int_a^b dx\ 4\pi\rho(x) \Phi(x) \tag*{23.7}\\
 \Rightarrow \quad    \int_a^b\ dx   \frac{d
U(x)}{dx}\Phi'(x) &= \int_a^b\ dx 4\pi\rho(x) \Phi(x) .
\tag*{23.8}\end{align}$$

Equation (23.8) is the *weak* form of the PDE,
“weak” in the sense that it does not require the existence of the second
derivative of $U$, or the continuity of $\rho$. Because the approximate and
exact solutions are related by the integral of their difference over the entire
domain, the algorithm provides a global best agreement between the two.

### 23.4.2  Galerkin Spectral Decomposition <a id="23.4.2"></a>

The approximate solution to the weak PDE proceeds via three steps. First
we split the full domain of the PDE into subdomains called *elements*,
then we find approximate solutions within each element, and finally we
match the elemental solutions onto each other. For our 1-D problem, the
subdomain elements are straight lines of equal length, while for the 2-D
problem to be considered soon, the elements are triangles (Figure 23.4).

|A|B| 
|:- - - :|:- - - :| 
|![image](Figs/Fig23_2a.png)|![image](Figs/Fig23_2b.png)|

**Figure 23.2** Basis functions used in finite-elements solution of the 1-D Laplace
equation. *A:* A set of overlapping basis functions $\phi_\textit{i}$. Each
function is a triangle from $\textit{x}_{\textit{i}-\text{1}}$ to
$\textit{x}_{\textit{i}+\text{1}}$. *Middle:* A Piecewise-linear function. *B:* A
piecewise-quadratic function.

The critical step in the finite-elements method is expansion of the solution $U$
in terms of a set of basis functions $\phi_i$:

$$\tag*{23.9} U(x) \simeq
{\sum_{j=0}^{N-1}} \alpha_j \phi_j(x).$$

Even when the basis functions are not
sines or cosines, this expansion is still called a *spectral* decomposition. We will
choose $\phi_i$’s that are convenient for computation, and so the solution
reduces to determining the unknown expansion coefficients $\alpha_j$. Later,
in order to satisfy the boundary conditions, we will add an additional term to
this expansion.

Considerable study has gone into determining the effectiveness of different
basis functions $\phi_i$ that are used to represent the solution on the finite
elements. If the sizes of the finite elements are made sufficiently small, then
good accuracy is obtained with simple piecewise-continuous basis functions
$\phi_i$. For our 1-D problem we use finite *elements* that are line segments
between $x_i$ and $x_{i+1}$, and we use *basis functions*, representing the
solution on each line segment, that have the form of triangle or “hats” between
$x_{i-1}$ and $x_{i+1}$ (Figure 23.2). We also require that each basis function
equals 1 at the $x_i$ vertex, $\phi_i(x_i)=1$:

$$\tag*{23.10}
\phi_i(x)= \begin{cases}
  0, &\mbox{for } x<x_{i-1}, \  \mbox{or } \ x>x_{i+1}, \\
  \frac{x-x_{i-1}}{h_{i-1}}, &\mbox{for } \ x_{i-1}\leq x\leq x_i,\\
  \frac{x_{i+1}-x}{h_i}, & \mbox{for } \  x_{i}\leq x \leq x_{i+1}.
  \end{cases}\  (h_i=x_{i+1}-x_i),$$

  Because this choice means that each
basis function equals 0 or 1 at the nodes, 

$$\tag*{23.11}
 \phi_i(x_j)= \delta_{ij},$$ 
 
the values of the expansion coefficients
$\alpha_i$ must equal the values of the (still unknown) solution at the nodes:

$$\begin{align}
\tag*{23.12}
U(x_i)& \simeq   \sum_{i=0}^{N-1}\alpha_i\phi_i(x_i) =
\alpha_i\phi_i(x_i) = \alpha_i, \\
\Rightarrow \quad U(x) & \simeq   \sum_{j=0}^{N-1}
U(x_j)\phi_j(x).\tag*{23.13}\end{align}$$

Equation (23.13) makes it clear that
the expansion in terms of basis functions is essentially an interpolation between
the actual solution at the nodes.

#### 23.4.2.1 Solution via Linear Equations <a id="23.4.2.1"></a>

Because the basis functions $\phi_i$ in (23.9) are known, solving for $U(x)$
involves determining the coefficients $\alpha_j$, which, as we just said, are the
unknown values of the true solution $U(x)$ on the nodes. We determine those
values by substituting the expansions for $U(x)$ and $\Phi(x)$ into the weak
form of the PDE (23.8). This converts the integral equation into a set of
simultaneous linear equations. As discussed in [Chapter 6](CP06.ipynb), there is
a standard matrix form for a set of linear equations, 

$$\tag*{23.13}
A\mathbf{y} = \mathbf{b}.$$ 

Our equations fit that, with $\mathbf{y}$ a vector
of unknowns, and where we still need to specify the known *stiffness matrix*
$A$ and the known load matrix $\mathbf{b}$. To that end, we substitute the
expansion $U(x) \simeq {\sum_{j=0}^{N-1}} \alpha_j \phi_j(x)$ into the weak
form (23.8) to obtain:

$$
\int_a^b dx \frac{d}{dx}\left(\sum_{j=0}^{N-1} \alpha_j
\phi_j(x)\right)\frac{d\Phi}{dx} =\int_a^b dx4\pi\rho(x)
\Phi(x).$$

By successively selecting $\Phi(x) =\phi_0, \phi_1, \ldots ,\phi_{N-1}$, we obtain
$N$ simultaneous linear equations for the unknown $\alpha_j$’s:

$$\tag*{23.15}
\int_a^b dx  \frac{d}{dx}\left(\sum_{j=0}^{N-1} \alpha_j
\phi_j(x)\right) \frac{d\phi_i}{dx}= \int_a^b dx   4\pi\rho(x)
\phi_i(x),  \quad i=0,   N-1 .$$

We factor out the unknown $\alpha_j$’s and write the equations out explicitly:

$$\begin{align}
\alpha_0 \int _a^b \phi_0^{\prime} \phi_0^{\prime}  dx + \alpha_1
\int _a^b \phi_0^{\prime} \phi_1^{\prime} dx+ \cdots
+\alpha_{N-1} \int _a^b \phi_0^{\prime}\phi_{N-1}^{\prime} dx & = \int _a^b
4\pi\rho\phi_0 dx,\\
\alpha_0 \int _a^b \phi_1^{\prime} \phi_0^{\prime}  dx + \alpha_1
\int_a^b \phi_1^{\prime} \phi_1^{\prime} dx + \cdots +
\alpha_{N-1} \int _a^b \phi_1^{\prime} \phi_{N-1}^{\prime} dx
& = \int _a^b 4\pi\rho\phi_1 dx ,\\
\ddots \
\alpha_0 \int _a^b \phi_{N-1}^{\prime} \phi_0^{\prime} dx +
\alpha_1  \int \cdots + \alpha_{N-1} \int _a^b \phi_{N-1}^{\prime}
 \phi_{N-1}^{\prime} dx&=   \int _a^b 4\pi\rho\phi_{N-1}  dx.\end{align}$$

Because we have chosen the $\phi_i$’s to be the simple hat functions, the
derivatives are easy to evaluate analytically (for other bases they can be carried
out numerically):

$$\begin{align}
\tag*{23.16}
\frac{d \phi_{i, i+1}} { dx}  \ =\
\begin{cases}
0, & x<x_{i-1}, \mbox{or}\ x_{i+1}< x, \\
\frac{1}{h_{i-1}}, &     x_{i-1}\leq x\leq x_i,\\
\frac{-1}{h_i}, &       x_{i}\leq x \leq x_{i+1},\\
    0, &    x<x_{i}, \ \mbox{or}\ x_{i+2}< x\
  \frac{1}{h_{i}}, &   x_{i}\leq x\leq x_{i+1},\\
 \frac{-1}{h_{i+1}}, &   x_{i+1}\leq x \leq x_{i+2}.
 \end{cases}\end{align}$$
 The integrations are now fairly simple:

$$\begin{align}
\tag*{23.17}
\int_{x_{i-1}}^{x_{i+1}}dx (\phi_{i}^{'})^{2}  & =
\int_{x_{i-1}}^{x_{i}} dx  \frac{1}{(h_{i-1})^2} +
\int_{x_{i}}^{x_{i+1}} dx \frac{1}{h_i^2} = \frac{1}{h_{i-1}}
+\frac{1}{h_{i}},\\
\int_{x_{i-1}}^{x_{i+1}}dx  \phi_{i}^{'} \phi_{i+1}^{'} & =
\int_{x_{i-1}}^{x_{i+1}}dx  \phi_{i+1}^{'} \phi_{i}^{'} =
\int_{x_i}^{x_{i+1}}dx \frac{-1}{h_i^2} = -\frac{1}{h_i},\tag*{23.18}\\
\int_{x_{i-1}}^{x_{i+1}}\ dx   (\phi_{i+1}^{'})^{2} & =
\int_{x_i}^{x_{i+1}}dx   (\phi_{i+1}^{'})^{2} =
\int_{x_i}^{x_{i+1}}dx  \frac{+1}{h_i^2} = +\frac{1}{h_i}.\tag*{23.19}\end{align}$$

We rewrite these equations in the standard matrix form (23.13) with
$\mathbf{y}$ constructed from the unknown $\alpha_j$’s, and the tridiagonal
stiffness matrix $A$ constructed from the integrals over the derivatives:

$$\begin{align}\tag*{23.20}
\mathbf{y}  & =  \begin{bmatrix}
 \alpha_0 \\
 \alpha_1\\
 \ddots\\
 \alpha_{N-1}
 \end{bmatrix},\quad
\mathbf{b}= \begin{bmatrix}
 \int_{x_{0}}^{x_{1}} dx  4\pi\rho(x)\phi_{0}(x)\\
 \int_{x_{1}}^{x_{2}} dx  4\pi\rho(x)\phi_{1}(x)\\
 \ddots \\
 \int_{x_{N-1}}^{x_{N}} dx 4\pi\rho(x)\phi_{N-1}(x)
 \end{bmatrix},\\
A & =   \begin{bmatrix}
 \frac{1}{h_0}+\frac{1}{h_1} & -\frac{1}{h_1} & -\frac{1}{h_0} & 0 & \ldots\\
-\frac{1}{h_1} & \frac{1}{h_1}+ \frac{1}{h_2} & -\frac{1}{h_2} &0 &\ldots\\
0 & -\frac{1}{h_2} & \frac{1}{h_2}+ \frac{1}{h_3} & -
\frac{1}{h_3} &\ldots\\
\ddots & \ddots & - \frac{1}{h_{N-1}}  & - \frac{1}{h_{N-2}} &
\frac{1}{h_{N-2}}+\frac{1}{h_{N-1}}
\end{bmatrix}.\tag*{23.21}\end{align}$$

The elements in $A$ are just
combinations of inverse step sizes and so do not change for different
charge densities $\rho(x)$. This is part of what makes FEM so efficient
once set up. The elements in $\mathbf{b}$ do change for different
$\rho$’s, but the required integrals can be performed analytically or
with Gaussian quadrature ([Chapter 5, *Differentiation &
Integration*](CP05.ipynb)). Once $A$ and $\mathbf{b}$ are computed,
highly efficient methods from a linear algebra package are used to solve
the matrix equations for $\mathbf{y}$, and thus the expansion
coefficients $\alpha_j$.

#### 23.4.2.2 Dirichlet Boundary Conditions <a id="23.4.2.2"></a>

Because the basis functions vanish at the endpoints, a solution expanded in
them must also vanishes there. This will not do in general, and so we must add
to our general solution $U(x)$, a particular solution $U_a\phi_0(x)$ that
satisfies the boundary conditions \[[Li(14)](BiblioLinked.html#Li)\]:

$$\tag*{23.22} U(x)=
{\sum_{j=0}^{N-1}} \alpha_j\phi_j(x) + U_a\phi_N(x)
\hspace{5ex}\mbox{(satisfies boundary conditions),}$$

where
$U_a=U(x_a)$. We substitute $U(x)-U_a\phi_0(x)$ into the weak form of the
PDE to obtain $(N+1)$ simultaneous equations, still of the form $\mathbf{A
y}=\mathbf{b}$, but now with

$$\tag*{23.23}
A = \begin{bmatrix} A_{0,0} &
\cdots & A_{0,N-1}& 0 \ & \ddots & & \ A_{N-1,0} & \cdots & A_{N-1,N-1}& 0
\\
 0 & 0 & \cdots & 1\
\end{bmatrix}, \quad
\mathbf{b'} = \begin{bmatrix}
b_0 - A_{0,0}U_a\
\ddots\
b_{N-1}-A_{N-1,0}U_a\ U_a
\end{bmatrix}.$$

This is equivalent to adding a unit element to $A$ and adding a new load vector
element: 

$$\tag*{23.24} b'_i= b_i-A_{i,0} U_a, \quad i=1,\ldots, N-1,\quad b'_N
= U_a.$$ 

To impose the boundary condition at $x=b$, we again add a particular
solution $U_b\phi_{N-1}(x)$ and substitute it into the weak form to obtain

$$\tag*{23.25} b'_i = b_i-A_{i,N-1} U_b, \quad i=1,
\ldots, N-1\quad b'_N = U_b.$$ 

So now we need to solve the linear equations
$A\mathbf{y}=\mathbf{b'}$. For 1-D problems, 100–1000 equations are
common, while for 3-D problems there may be millions. Because the number of
calculations varies approximately as $N^2$, it is important to utilize an efficient
and accurate algorithm, because otherwise round-off error can easily dominate
the solution.

![image](Figs/Fig23_3.png)

 **Figure 23.3** Exact (line) *versus* FEM
solution (points) for the two-plate problem for $\textit{N}=\text{3}$
and $\textit{N}=\text{11}$ finite elements ($N=3$ displaced upwards for
clarity). On this scale the $N = 11$ solution IS identical to the exact
one.

## 23.5  1-D FEM Implementation and Exercises <a id="23.5"></a> 

In Listing 23.1 we give our program `LaplaceFEM_1D.py` that determines
the 1-D FEM solution, and in Figure 23.3 we show that solution. We see
on the left of the figure that three elements do not provide even visual
agreement with the analytic result, whereas $N=11$ elements do.

1. Examine the FEM solution for the choice of parameters 

$$\tag*{23.26}
    a = 0, \quad b = 1, \quad U_a = 0, \quad U_b =1.$$

2.  Generate your own triangulation by assigning explicit $x$ values at
    the nodes over the interval $[0,1]$.

3.  Start with $N = 3$ and solve the equations for $N$ values up
    to 1000.

4.  Examine the stiffness matrix $A$ and ensure that it is triangular.

5.  Verify that the integrations used to compute the load vector
    $\mathbf{b}$ are accurate.

6.  Verify that the solution of the linear equation
    $A\mathbf{y}=\mathbf{b}$ is correct.

7.  Plot the numerical solution for $U(x)$ for $N =$ 10, 100, and 1000,
    and compare with the analytic solution.

8.  The log of the relative global error (number of significant figures)
    is 
    
    $$\tag*{23.27}
    {\cal E} = \log_{10}\left|\frac{1}{b-a}\int_a^bdx \frac{U_{\text{FEM}}(x) -U_{\text{exact}}(x)}{U_{\text{exact}}(x)}\right|.$$
    
    Plot the global error <span>*versus*</span> $x$ for $ N =$ 10, 100,
    and 1000.

[**Listing 23.1
  LaplaceFEM_1D.py**](http://science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/LaplaceFEM_1D.py)
provides a finite-elements method solution of the 1-D Laplace equation
via a Galerkin spectral decomposition. The resulting matrix equations
are solved with Matplotlib. Although the algorithm is more involved than
the solution via relaxation.

### 23.5.1  1-D Exploration <a id="23.5.1"></a>

1.  Modify your program to use piecewise-quadratic functions for
    interpolation, and compare the results obtained to those obtained
    with the linear functions.

2.  Explore the resulting electric potential and check that the charge
    distribution between the plates has the explicit $x$ dependence
    
    $$\tag*{23.28}
    \rho(x) = \frac{1}{4\pi} \left\{ \begin{array}{lll}
    \frac {1}{2} -x,\\
    \sin x,\\
    1 \mbox{at } x=0, \ \ -1 \ \mbox{at}\ x=1 \ \ \mbox{(a capacitor)}.
    \end{array}\right.$$

## 23.6  Extension to 2-D Finite Elements <a id="23.6"></a>

The steps followed to derive the 2-D finite elements method are similar
to those for the 1-D method, with the big difference being that the
finite elements are now 2-D triangles as opposed to 1-D lines.
Figure 23.4 shows how an arbitrarily shaped domain might be decomposed
into triangles. Although life is simpler if all the finite elements are
the same size and shape, this is not necessary, and, indeed, as we seen
in the figure, higher precision and faster run times maybe obtained by
picking smaller domains in regions where the solution is known to vary
rapidly, and picking larger domains in regions of slow variation. As you
can imagine, 2-D and 3-D FEM can get rather complicated, but not to
worry, we will just outline the 2-D method and refer the interested
reader to \[[Polycarpou(06)](BiblioLinked.html#poly)\] and \[[Reddy(93)](BiblioLinked.html#red)\] for fuller discussions.

|A|B| 
|:---:|:---:|
|![image](Figs/Fig23_4a.png)|![image](Figs/Fig23_4b.png)|


**Figure 23.4** *A:* Decomposition of a domain into triangular elements.
Smaller triangles are used in regions of rapid variation and larger
triangles are used in regions of slow variation. Discretization errors
occur at boundaries. *B:* A decomposition of a rectangular domain into
32 right triangles on a mesh with 25 nodes.

We extend our previous 1-D method to solve the 2-D version of the Laplace
equation (19.4), $$\tag*{23.29}
\frac{\partial^2 U}{\partial x^2}+\frac{\partial^2 U}{\partial y^2}=0.$$
There are now 2-D Dirichlet boundary conditions:
$$\tag*{23.30} U(x,0) =0,
\qquad U(x,h) =U_0, \qquad U(0,y) =0, \qquad U(w,y) =0.$$
Here $h$ is the
height and $w$ is the width of the rectangular domain in which we desire a
solution. Because our problem domain is now rectangular, it is easy to divide it
into right triangles, as we do on the right of Figure 23.4.

### 23.6.1  Weak Form of PDE <a id="23.6.1"></a>

For the 2-D problem, the weak form of the PDE again follows from multiplying
both sides of the PDE by the trial solution $\Phi$, and then integrating
\[[Polycarpou(06)](BiblioLinked.html#poly)\]:

 $$\tag*{23.31}
 \int\int_\Omega \left( \frac{\partial\Phi} {\partial x} \frac{\partial U} {\partial x} + \frac{\partial\Phi} {\partial y} \frac{\partial U} {\partial y}\right)dx dy  =  \oint_\Gamma  \left(\frac{\partial U}{\partial x} n_x + \frac{\partial U}{\partial y} n_y \right)dl .$$

Here $\Omega$ is a surface boundary of the domain in which we seek a
solution, $\Gamma$ is a perimeter around the surface, $U$ is the solution of
the PDE, and $n_x$ and $n_y$ are outward-facing unit normal to $\Gamma$.
For Dirichlet boundary conditions the contribution of the line integral on the
RHS vanishes.

### 23.6.2  Galerkin’s Spectral Decomposition <a id="23.6.2"></a>

As in the 1-D method, the approximate solution $U(x,y)$ is expanded in a set
$\phi_i(x,y)$ of basis functions, in this case 2-D functions:

$$\tag*{23.32}
    U(x,y) =\sum_{j=0}^{N-1} \alpha_j \phi_j(x,y).$$
    
After setting $U=\phi_j $ for $j=1,2.....,N-1 $, the weak form of the PDE
becomes a set of linear equations:

$$\begin{align} 
  \int \int_\Omega \left[ \left( \frac{\partial\phi_i}{\partial x} \right) \left(\sum_{j=0}^{N-1} \alpha_j \frac{\partial \phi_j}{\partial x} \right)
  +\left(\frac{\partial\phi_i}{\partial y}\right) \left(\sum_{j=0}^{N-1} \alpha_j \frac{\partial \phi_j}{\partial y}\right) \right] dx dy 
 =   \quad  \oint_\Gamma \left(\frac{\partial U}{\partial x} n_x + \frac{\partial U}{\partial y} n_y\right)dl .\tag*{23.33}\end{align}$$

We rewrite these equations in the standard matrix form (23.13) for linear
equations:

$$\tag*{23.34}
\begin{bmatrix}
A_{11}& A_{12}& \cdots &A_{1N}\cr A_{21}& A_{22}& \cdots &A_{2N}\cr
        \vdots & \vdots & \ddots &\vdots\cr A_{N1}& A_{N2}&\cdots&A_{NN}
\end{bmatrix}
\begin{bmatrix}
 U_1\cr U_2\cr \vdots\cr U_n
\end{bmatrix} = \begin{bmatrix} b_1\cr  b_2\cr \vdots\cr b_n \end{bmatrix}.$$

Here the $U_i$’s is a vector of unknowns, the *stiffness matrix* elements are
$$\tag*{23.35} A_{ij} = -\int\int_\Omega \left( \frac{\partial\phi_i}{\partial x}
\frac{\partial \phi_j} {\partial x} +\frac{\partial\phi_i}{\partial y}\frac{\partial
\phi_j}{\partial y}\right) dx dy ,$$ and the load vector $\mathbf{b}$ is given by
(23.20).

![image](Figs/Fig23_5.png) 

**Figure 23.5** *Left:* Linear triangular
elements in the x-y plane. *Right:* Linear triangular element (master
element) in the $\xi\eta$ plane.

### 23.6.3  Triangular Elements <a id="23.6.3"></a>

Triangular elements are often used in 2-D FEM because they can be fit
into many arbitrary geometries with little overlap and with little
discretization error at the boundary edges (see Figure 23.4). As we see
in Figure 23.5 left, we take these elements to be triangles of arbitrary
shape, with the CCW arrow indicating the direction in which the nodes
are numbered. While it is easier to fit arbitrary shaped triangles into
a general region, it is easier to do mathematics with right triangles,
such as the master triangle shown in Figure 23.5 right. The latter have
their orthogonal sides lying along the $\xi$ and $\eta$ axes, with the
$(x,y)$ and $(\xi,\eta)$ coordinates related by a linear coordinate
transformation.

These master triangles are the linear interpolation functions in the $\xi$ and
$\eta$ variables that are used in 2-D FEM. For example, the linear function for
node 1 has the form $$\tag*{23.36}
\phi_1(\xi,\eta) = a+b \xi+c \eta.$$ The constants are determined by
evaluating the functions at each node, for example,

$$\begin{align}\tag*{23.37}
\phi_1(0,0) & =a=1, \qquad \phi_1(1,0)  =1+b=0 \Rightarrow b=-1,\\
\phi_1(0,1) & =1+c=0\Rightarrow c=-1, \tag*{23.38}\\
\Rightarrow\quad \phi_1(\xi,\eta) & = 1 -\xi-\eta\tag*{23.39}\end{align}$$

Similar evaluations at the other nodes yield \[[Polycarpou(06)](BiblioLinked.html#poly)\]:

$$\tag*{23.40}
 \phi_2 =\xi, \qquad \phi_3=\eta.$$
 
With these interpolation functions
in hand, it is possible to express the $x$ and $y$ coordinates of any point inside
an element in terms of the master coordinates:

$$\begin{align}\tag*{23.41}
 x &=x_1+\bar{x}_{21} \xi +\bar{x}_{31} \eta, \\
 y & =y_1+\bar{y}_{21} \xi +\bar{y}_{31} \eta,\tag*{23.42}\\
\bar{x}_{ij} &\stackrel{\rm def}{\ \   =\ \   } x_i-x_j ,  \quad    \bar{y}_{ij} \stackrel{\rm def}{\ \   =\ \   } y_i-y_j.\tag*{23.43}\end{align}$$

Next we take these discrete forms for the interpolation functions, return to the
Galerkin spectral decomposition, and use (23.35) to evaluate the $A$ matrix.
The required derivatives are evaluated using the chain rule:

$$\begin{align}
\tag*{23.44}
\frac{\partial \phi}{\partial \xi} & =\frac{\partial \phi}{\partial x}\frac{\partial x}{\partial\xi}+\frac{\partial \phi}{\partial y}\frac{\partial y}{\partial\xi},
\\
\frac{\partial \phi}{\partial \eta} & =\frac{\partial \phi}{\partial x}\frac{\partial x}{\partial\eta}+\frac{\partial \phi}{\partial y}\frac{\partial y}{\partial\eta}.\tag*{23.45}\end{align}$$

We write these equations in matrix form as:

$$\tag*{23.46}
\begin{bmatrix}
 {\partial \phi} /{\partial \xi} \cr  {\partial \phi}/{\partial \eta}
\end{bmatrix}
= \begin{bmatrix}{\partial x}/{\partial \xi} &  {\partial y}/ {\partial \xi} \cr
{\partial x}/{\partial \eta} &  {\partial y}/{\partial \eta}
\end{bmatrix}
\begin{bmatrix}
 {\partial \phi}/{\partial x}  \cr
            {\partial \phi}/{\partial y}
            \end{bmatrix},$$

where the $2\times2$ matrix that defines
the coordinate transformation between the $(x,y)$ and the $(\xi,\eta)$
derivatives is called the *Jacobian* matrix $J$. After substitution of the explicit
forms for the $\phi$’s, the Jacobian takes the simple form:

$$\tag*{23.47} J=
\begin{bmatrix}
 \bar{x}_{21} &  \bar{y}_{21}  \cr \bar{x}_{31}  & \bar{y}_{31}
\end{bmatrix}.$$

Likewise, the derivatives in the $A$ matrix can be
expressed in terms of the $x$ and $y$ derivatives by using the inverse of the
Jacobain matrix:

$$\begin{align}
\tag*{23.48}
\begin{bmatrix}
 \frac{\partial \phi}{\partial x} \cr
           \frac{\partial \Phi}{\partial y} \end{bmatrix} &=
                    J^{-1} \begin{bmatrix}  \frac{\partial \phi}{\partial \xi} \cr
           \frac{\partial \Phi}{\partial \eta},
          \end{bmatrix} \\
J^{-1} &= \frac{1}{\left|J\right|}
\begin{bmatrix}
\bar{y}_{31} & -\bar{y}_{21} \cr
             -\bar{x}_{31}  & \bar{x}_{21}  \end{bmatrix}, \quad
|J| \equiv \det(J) = \bar{x}_{2}
\bar{y}_{31}-\bar{x}_{31}\bar{y}_{21}.\tag*{23.49}\end{align}$$

Continued evaluation of the Galerkin matrix elements yields:

$$\begin{align}
\tag*{23.50}
\begin{bmatrix}
\frac{\partial \phi_1} {\partial x} \cr
           \frac{\partial \phi_1}{\partial y}
\end{bmatrix} & = \frac{1}{|J|}
\begin{bmatrix} \bar{y}_{31} & \bar{-y}_{21}  \cr
             \bar{-x}_{31 } & \bar{x}_{21 } \end{bmatrix}
\begin{bmatrix} \frac{\partial \phi_1}{\partial \xi} \cr
           \frac{\partial \phi_1}{\partial \eta}  \end{bmatrix}  =
                    \frac{1}{|J|} \begin{bmatrix} \bar{y}_{31}  & -\bar{y}_{21}  \cr
             -\bar{x}_{31}  & \bar{x}_{21}   \end{bmatrix} \begin{bmatrix} -1\cr
                        -1 \end{bmatrix}\\
                         &=          \frac{1}{|J|} \begin{bmatrix} \bar{y}_{21}  & -\bar{y}_{31} \cr
             \bar{x}_{31} & -\bar{x}_{21}  \end{bmatrix} =
                        \frac{1}{|J|}\begin{bmatrix} \bar{y}_{23} \cr
                        \bar{x}_{32} \end{bmatrix}.\tag*{23.51}\end{align}$$

After similar evaluations for $\phi_2$ and $\phi_3$, we obtain the six needed
derivatives:

$$\begin{align}
\tag*{23.52}
\frac{\partial\phi_1}{\partial x} &= \frac{\bar{y}_{23 }}{|J|}, \qquad
\frac{\partial\phi_1}{\partial y}  = \frac{\bar{x}_{32} }{|J|},\\
\frac{\partial\phi_2}{\partial x} &= \frac{\bar{y}_{31} }{|J|}, \qquad
\frac{\partial\phi_2}{\partial y}  = \frac{\bar{x}_{13}}{|J|},\tag*{23.53}\\
\frac{\partial\phi_3}{\partial x} &= \frac{\bar{y}_{12}}{|J|}, \qquad
\frac{\partial\phi_3}{\partial y}  = \frac{\bar{x}_{21}}{|J|}.\tag*{23.54}\end{align}$$

### 23.6.4  Solution as Linear Equations <a id="23.6.4"></a>

The final evaluations of the stiffness matrix elements are made using the $\xi$
and $\eta$ coordinates, for example, $$\tag*{23.55}
A_{11}=-\int_0^1\int_0^{1-\eta}\left[\frac{\bar{y}_{23}^2+\bar{x}_{32}^2}{|J|^2}\right]|J|
d\xi d\eta.$$ These elements are found to form a symmetric matrix with values:

$$\begin{align}
\tag*{23.56}
A_{12} &=  A_{21}=- \frac{\bar{y}_{23}\bar{y}_{31}+\bar{x}_{32} \bar{x}_{13}}{2|J|},
\qquad A_{11}   = - \frac{\bar{y}_{23}^2+\bar{x}_{32}^2}{2|J|}, \\
 A_{13}   &=A_{31}= - \frac{\bar{y}_{23}\bar{y}_{12}+\bar{x}_{32}\bar{x}_{21}}{2|J|} ,
 \qquad A_{22}   =- \frac{\bar{y}_{31}^2+\bar{x}_{13}^2}{2J} , \tag*{23.57}\\
 A_{23}   &=A_{32} =- \frac{\bar{y}_{31}\bar{y}_{12}+\bar{x}_{13}\bar{x}_{21}}{2|J|} ,
 \qquad A_{33}  =- \frac{\bar{y}_{12}^2+\bar{x}_{21}^2}{2J}.\tag*{23.58}\end{align}$$

Next we evaluates the coordinate transformations:

$$\begin{align}
\tag*{23.59}
\begin{bmatrix} x-x_1\cr y-y_1 \end{bmatrix}  & =
\begin{bmatrix} \bar{x}_{21} & \bar{x}_{31} \cr \bar{y}_{21}&\bar{y}_{31}\end{bmatrix}
\begin{bmatrix} \xi\cr \eta \end{bmatrix} ,\\
\begin{bmatrix} \xi \cr \eta \end{bmatrix}  & =
\frac{1}{\bar{x}_{21} \bar{y}_{31} - \bar{x}_{31} \bar{y}_{21}}
\begin{bmatrix} \bar{y}_{31}  & -\bar{x}_{31} \cr -\bar{y}_{21} & \bar{x}_{21} \end{bmatrix}
\begin{bmatrix} x-x_1\cr y-y_1 \end{bmatrix}.\tag*{23.60}\end{align}$$

After substituting for $\xi$ and $\eta$, we are left with the desired
interpolation functions expressed in terms of just $x$ and $y$.

### 23.6.5  Imposing Boundary Conditions <a id="23.6.5"></a>

The procedure to impose Dirichlet’s boundary conditions for the 2-D case
is essentially the same as for the 1-D case, with it now applied to all
nodes that lie on the boundary $\Gamma$.

[**Listing 23.1 LaplaceFEM_2D.py**](http://science.oregonstate.edu/~rubin/Books/CPbook/Codes/PythonCodes/LaplaceFEM_2D.py) solves the 2-D Laplace equation using a finite elements method.

### 23.6.6  FEM 2D Implementation & Exercise <a id="23.6.6"></a>

As shown on the right of Figure 23.4, our application of 2-D FEM has the
solution domain covered by a collection of triangular elements. Each
triangle in the mesh is numbered, in this case from 1 to 32. In
addition, the three vertices of each triangle are numbered in a
counter-clockwise direction from 1 to 3. Next, each node in the mesh
(the dark circles in Figure 23.4 where lines intersect) are numbered, in
this case from 1 to 25. Accordingly, the stiffness matrix $A$ in (23.33)
has dimension $25 \times 25$, while the load vector $\mathbf{b}$ has
dimension $25 \times 1$.

Listing 23.2 presents our implementation of the 2-D FEM solution to the
2-D Laplace equation, based on the Matlab code of \[[Polycarpou(06)](BiblioLinked.html#poly)\]. It
utilizes 800 elements and 441 nodes. The output of this code is
essentially the same as our solution to the same problem using the
finite differences method.

### 23.6.7  FEM 2D Exercises <a id="23.6.7"></a>

1.  Examine the effect of varying the domain height and width, as well
    as the number of elements.

2.  Compare this numerical solution to the analytic one (the Fourier
    series in §19.3) and determine how the precision changes as the
    number of elements is varied.

3.  Modify the program so that it solve the parallel plate capacitor
    problem and compare to the finite differences solution.


```python

```
